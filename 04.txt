import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import numpy as np

# load the housing data from the scikit-learn library
from sklearn import datasets 
data = datasets.load_boston()
df = pd.DataFrame(data.data,columns=data.feature_names)
df

#We print the value of the boston_dataset to understand what it contains
print(data.keys())

#We can see that the target value Price is missing from the data. We create a new column of target values and
add it to the dataframe.
data['Price'] = data.target
df.head()

#Info of Boston Dataset
df.info()
df.describe()

# Data preprocessing After loading the data, it’s a good practice to see if there are any missing values in the data. We count the
number of missing values for each feature using isnull().
df.isnull().sum()

#We will use the heatmap function from the seaborn library to plot the correlation matrix.
sns.heatmap(df.corr(), annot=True)

#Preparing the data for training the model We concatenate the LSTAT and RM columns using np.c_ provided by the numpy library.
from sklearn.model_selection import train_test_split
x = pd.DataFrame(np.c_[df.LSTAT, df.RM], columns=['LSTAT', 'RM'])
y = data.Price
x

X_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size=0.2, random_state=5)

#We use scikit-learn’s LinearRegression to train our model on both the training and test sets.
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train, Y_train)

y_pred = model.predict(X_test)


#TSS represents the total sum of squares Results of Linear Regression i.e. Mean Squared Error and R2 Score.
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

rmse = np.sqrt(mean_squared_error(Y_test, y_pred))
r2 = r2_score(Y_test, y_pred)

print('RMSE is: {}'.format(rmse))
print('R2  Score is: {}'.format(r2))

sample_data = [[6.89, 9.99]]

price = model.predict(sample_data)
print("Selling price for the house is ${:,.2f}".format(price[0]))

